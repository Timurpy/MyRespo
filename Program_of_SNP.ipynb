{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGMcKloqwoL1WyQqzoDHxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timurpy/MyRespo/blob/main/Program_of_SNP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup as BS\n",
        "\n",
        "\n",
        "def table_t_finder(info_main_table):\n",
        "    global Gene\n",
        "    Gene = \"\"\n",
        "    for paragraph in info_main_table.find_all(\"tr\"):\n",
        "        columns = paragraph.find_all(\"td\")\n",
        "        if len(columns) > 1:\n",
        "            column1_text = columns[0].get_text().strip()\n",
        "            column2_text = columns[1].get_text().strip()\n",
        "\n",
        "            # Save info about Gene\n",
        "            if column1_text == \"Gene\":\n",
        "                Gene = column2_text\n",
        "\n",
        "def div_p_finder(info_div):\n",
        "    global disease_info\n",
        "    global gene_info\n",
        "    disease_info = \"\"\n",
        "    gene_info = \"\"\n",
        "    j = 0\n",
        "    for paragraph in info_div.find_all(\"p\"):\n",
        "        text = paragraph.get_text()\n",
        "        if j >= 7:\n",
        "            break\n",
        "        elif \"gene\" in text.lower():\n",
        "            gene_info += text + \"\\n\"\n",
        "            j += 1\n",
        "\n",
        "# Reading SNP_id\n",
        "SNP_id = open(r'/content/spisok SNP.txt', 'r')\n",
        "listid = SNP_id.read().splitlines()\n",
        "list_of_ID = []\n",
        "for i in listid:\n",
        "    list_of_ID.extend(i.split(', '))\n",
        "\n",
        "# Reading the \"raw\" vcf and remove the spaces (Optional)\n",
        "vcf_inp = open('/content/spisok SNP.txt', \"r\")\n",
        "vcf_out = open('/content/Full_spisok_SNP.txt', \"w\")\n",
        "for line in vcf_inp:\n",
        "   new_line = line.replace('\\t', ' ')\n",
        "   vcf_out.write(new_line)\n",
        "vcf_inp.close()\n",
        "vcf_out.close()\n",
        "\n",
        "with open('/content/Full_spisok_SNP.txt', 'r') as infile, open('/content/snp_python_sorted.txt', 'w') as outfile:\n",
        "    for line in infile:\n",
        "        if any(word in line for word in list_of_ID):\n",
        "            outfile.write(line)\n",
        "\n",
        "# Remove trash (; and etc.)\n",
        "with open('/content/snp_python_sorted.txt', 'r') as infile, open('/content/snp_python_sd.txt', 'w') as outfile:\n",
        "    for line in infile:\n",
        "        line = re.sub(';.*? ', ' ', line)\n",
        "        outfile.write(line)\n",
        "\n",
        "line1 = \"Chr Coord SNP_ID Before_mut After_mut Quality Other_inf(e.g.0/1-heterozygote)\\n\"\n",
        "filename = '/content/snp_python_sd.txt'\n",
        "def line_prepender(filename, line):\n",
        "    with open(filename, 'r+') as f:\n",
        "        content = f.read()\n",
        "        f.seek(0, 0)\n",
        "        f.write(line.rstrip('\\r\\n') + '\\n' + content)\n",
        "\n",
        "line_prepender(filename, line1)\n",
        "\n",
        "print(\"The program thinks...\")\n",
        "xe = 0\n",
        "\n",
        "# BIG FOR!\n",
        "for i in list_of_ID:\n",
        "\n",
        "    # SNPedia parsing\n",
        "    snp_id = i\n",
        "    url = \"https://www.snpedia.com/index.php/\" + snp_id  # Request to SNPpedia with our SNP\n",
        "\n",
        "    # Page request and HTML analysis using BeautifulSoup\n",
        "    response = requests.get(url)\n",
        "    soup = BS(response.text, \"html.parser\")\n",
        "\n",
        "    # Adding the desired tag\n",
        "    info_div = soup.find(\"div\", {\"class\": \"mw-content-ltr\"})\n",
        "    info_main_table = soup.find(\"div\", {\"class\": \"aside-right col-sm-4\"})\n",
        "\n",
        "    # Extracting information\n",
        "    try:\n",
        "        div_p_finder(info_div)\n",
        "    except:\n",
        "        gene_info = \"<b>NOT FOUND INFORMATION ABOUT GENE :(</b>\"\n",
        "\n",
        "    try:\n",
        "        table_t_finder(info_main_table)\n",
        "    except:\n",
        "        Gene = \"LOL :(\"\n",
        "        print(\"ATTANTION!\")\n",
        "\n",
        "    # Remove PMID\n",
        "    if gene_info not in \"<b>NOT FOUND INFORMATION ABOUT GENE :(</b>\":\n",
        "        gene_info = re.sub(r'\\[.*?\\]', ' ', gene_info)\n",
        "\n",
        "    vcf = open('/content/snp_python_sd.txt', \"r\")\n",
        "    df = pd.read_csv(vcf, delimiter=' ')\n",
        "\n",
        "    def pars_df(df):\n",
        "        for index, row in df.iterrows():\n",
        "            time_value = row[2]\n",
        "            if time_value == snp_id:\n",
        "                return row\n",
        "\n",
        "\n",
        "    report = pars_df(df)\n",
        "    report = pd.DataFrame(report)\n",
        "    html_report = report.to_html()\n",
        "\n",
        "    # Writing in html file\n",
        "    info_sum = soup.find_all(\"table\", class_=\"sortable\")\n",
        "    with open(f\"D:\\Project_test\\HTMLs\\{snp_id}.html\", \"w\", encoding=\"utf-8\") as table:\n",
        "        if Gene:\n",
        "            table.write(f\"<b>Gene - {Gene}</b>\\n\")\n",
        "        if info_sum == []:\n",
        "            info_sum = \"<b>Sorry, we didn't find information about significance of this SNP :(</b><br>(You may just scip this snip)\"\n",
        "        table.write('<br><br>' + str(info_sum) + '<br><br>' + gene_info + '<br><br>' + html_report + '<br></br>')\n",
        "        table.write(\"____________________________________________\" * 6 + '<br><br><br><br>')\n",
        "    xe += 1\n",
        "    print(str(xe) + 'th' + ' ready')\n",
        "\n",
        "print(\"Preparation of the final report...\")\n",
        "\n",
        "# Combined html\n",
        "html_dir = \"D:\\Project_test\\HTMLs\\\\\"\n",
        "combined_html = ''\n",
        "html_files = []\n",
        "\n",
        "for j in list_of_ID:\n",
        "    html_files.append(j + \".html\")\n",
        "\n",
        "for file in html_files:\n",
        "    with open(html_dir + file, 'r') as fi:\n",
        "        soup = BS(fi.read(), 'html.parser')\n",
        "    combined_html += str(soup)\n",
        "\n",
        "with open('D:\\Project_test\\combined.html', 'w', encoding=\"utf-8\") as fi:\n",
        "    fi.write(combined_html)\n",
        "\n",
        "print(\"Ready!\\thank you for using SNParser!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnFQwlONTIb",
        "outputId": "0a78595b-4d63-482b-ee76-efee98c0e8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program thinks...\n",
            "1th ready\n",
            "2th ready\n",
            "3th ready\n",
            "4th ready\n",
            "5th ready\n",
            "6th ready\n",
            "7th ready\n",
            "8th ready\n",
            "9th ready\n",
            "10th ready\n",
            "11th ready\n",
            "12th ready\n",
            "13th ready\n",
            "14th ready\n",
            "15th ready\n",
            "16th ready\n",
            "17th ready\n",
            "18th ready\n",
            "19th ready\n",
            "20th ready\n",
            "21th ready\n",
            "22th ready\n",
            "23th ready\n",
            "24th ready\n",
            "25th ready\n",
            "26th ready\n",
            "27th ready\n",
            "28th ready\n",
            "29th ready\n",
            "30th ready\n",
            "31th ready\n",
            "32th ready\n",
            "33th ready\n",
            "34th ready\n",
            "35th ready\n",
            "36th ready\n",
            "37th ready\n",
            "38th ready\n",
            "39th ready\n",
            "40th ready\n",
            "41th ready\n",
            "42th ready\n",
            "43th ready\n",
            "44th ready\n",
            "45th ready\n",
            "46th ready\n",
            "47th ready\n",
            "48th ready\n",
            "49th ready\n",
            "50th ready\n",
            "51th ready\n",
            "52th ready\n",
            "53th ready\n",
            "54th ready\n",
            "55th ready\n",
            "56th ready\n",
            "57th ready\n",
            "58th ready\n",
            "59th ready\n",
            "60th ready\n",
            "61th ready\n",
            "62th ready\n",
            "63th ready\n",
            "64th ready\n",
            "65th ready\n",
            "66th ready\n",
            "67th ready\n",
            "68th ready\n",
            "69th ready\n",
            "70th ready\n",
            "71th ready\n",
            "72th ready\n",
            "73th ready\n",
            "74th ready\n",
            "75th ready\n",
            "76th ready\n",
            "77th ready\n",
            "78th ready\n",
            "79th ready\n",
            "80th ready\n",
            "81th ready\n",
            "82th ready\n",
            "83th ready\n",
            "84th ready\n",
            "85th ready\n",
            "86th ready\n",
            "87th ready\n",
            "88th ready\n",
            "89th ready\n",
            "90th ready\n",
            "91th ready\n",
            "92th ready\n",
            "93th ready\n",
            "94th ready\n",
            "ATTANTION!\n",
            "95th ready\n",
            "Preparation of the final report...\n",
            "Ready!\thank you for using SNParser!\n"
          ]
        }
      ]
    }
  ]
}